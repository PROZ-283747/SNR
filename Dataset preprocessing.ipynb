{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adell.j\\anaconda3\\envs\\snr\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import kaggle\n",
    "\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess files from raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle.api.authenticate()\n",
    "#kaggle.api.dataset_download_files(dataset_name, path=raw_data_dir, unzip=True, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> !!! TODO: next steps should be: </span>\n",
    "    1. Take images from bee1 and bee2 dir and create folder bee and save them there\n",
    "    2. Take images from wasp1 and wasp2 dir and create foldet wasp and save them there\n",
    "    3. Delete: example_notebook, label_generator, labels.csv and README.md\n",
    "    4. Move all remaining folders one level up in a directory tree, to raw_data_dir directory.\n",
    "        \n",
    "<span style=\"color:red\"> !!! Now it has to be done manualy </span>      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of files and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = [f.name for f in os.scandir(raw_data_dir) if f.is_dir()]\n",
    "\n",
    "files = []\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(raw_data_dir, subdir)\n",
    "    files += [os.path.join(subdir_path, f.name) for f in os.scandir(subdir_path) if f.is_file()]\n",
    "\n",
    "# Remove not images from dataset\n",
    "not_jpg = [f for f in files if not f.endswith(\".jpg\")]\n",
    "files = [file for file in files if file not in not_jpg]\n",
    "\n",
    "# Sort files to maintain order\n",
    "files = sorted(files)\n",
    "\n",
    "labels = [file.split(\"\\\\\")[-2] for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = dict((label, index) for index, label in enumerate(sorted(set(labels))))\n",
    "encoded_labels = [label2index[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split files into training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_FILES  = len(files)\n",
    "NUMBER_OF_LABELS = len(label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(files,\n",
    "                                                                      encoded_labels,\n",
    "                                                                      test_size=TEST_SPLIT_FACTOR,\n",
    "                                                                      random_state=1969)\n",
    "\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(train_files,\n",
    "                                                                    train_labels,\n",
    "                                                                    test_size=VAL_SPLIT_FACTOR,\n",
    "                                                                    random_state=1969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7308\n",
      "2284\n",
      "1828\n",
      "11420\n"
     ]
    }
   ],
   "source": [
    "# TO DELETE\n",
    "print(len(train_files))\n",
    "print(len(test_files))\n",
    "print(len(val_files))\n",
    "print(len(train_files) + len(val_files) + len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> TODO: Data augmentation on: train_files, test_files, val_files </span>\n",
    "#### We have to remember also about augmenting labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare images in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = tf.image.encode_jpeg(\n",
    "        image,\n",
    "        optimize_size=True,\n",
    "        x_density=96,\n",
    "        y_density=96\n",
    "    )\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_prepare_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return prepare_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "test_images_ds  = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "val_images_ds   = tf.data.Dataset.from_tensor_slices(val_files)\n",
    "\n",
    "train_labels_ds = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "test_labels_ds  = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "val_labels_ds   = tf.data.Dataset.from_tensor_slices(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply preprocessing to images datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = train_images_ds.map(load_and_prepare_image, num_parallel_calls=4)\n",
    "test_images_ds  =  test_images_ds.map(load_and_prepare_image, num_parallel_calls=4)\n",
    "val_images_ds   =   val_images_ds.map(load_and_prepare_image, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images datasets to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = train_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "test_images_ds  =  test_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "val_images_ds   =   val_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "\n",
    "train_writer = tf.data.experimental.TFRecordWriter(train_images_file)\n",
    "test_writer  = tf.data.experimental.TFRecordWriter( test_images_file)\n",
    "val_writer   = tf.data.experimental.TFRecordWriter(  val_images_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Do not use the commented code below!!!</span>\n",
    "### ...unless you're 100% sure you know why are you doing this\n",
    "This will override our dataset and it will be no longer consistent with a previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_writer.write(train_images_ds)\n",
    " test_writer.write(test_images_ds)\n",
    " val_writer.write(val_images_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save labels datasets to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ds = train_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "test_labels_ds  =  test_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "val_labels_ds   =   val_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "\n",
    "train_writer = tf.data.experimental.TFRecordWriter(train_labels_file)\n",
    "test_writer  = tf.data.experimental.TFRecordWriter( test_labels_file)\n",
    "val_writer   = tf.data.experimental.TFRecordWriter(  val_labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Do not use the commented code below!!!</span>\n",
    "### ...unless you're 100% sure you know why are you doing this\n",
    "This will override our dataset and it will be no longer consistent with a previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.write(train_labels_ds)\n",
    "test_writer. write(test_labels_ds)\n",
    "val_writer.  write(val_labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snr)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
